{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"PqC4R7SGseKa","executionInfo":{"status":"ok","timestamp":1678093229270,"user_tz":-180,"elapsed":4709,"user":{"displayName":"Даниил Кравченко","userId":"18191217465303191452"}}},"outputs":[],"source":["import torch"]},{"cell_type":"markdown","metadata":{"id":"0J2RM8f5wP33"},"source":["## 2.1 Создание нейронов и полносвязных слоев"]},{"cell_type":"markdown","metadata":{"id":"_2ArJn_nsdZC"},"source":["2.1.1. Используя операции над матрицами и векторами из библиотеки `torch`, реализовать нейрон с заданными весами `weights` и `bias`. Прогнать вектор `inputs` через нейрон и вывести результат. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f4agkY9WqPwe"},"outputs":[],"source":["class Neuron:\n","  def __init__(self, weights, bias):\n","    # <создать атрибуты объекта weights и bias>\n","    self.weights = weights\n","    self.bias = bias\n","\n","  def forward(self, inputs):\n","    return torch.dot(self.weights, inputs) + self.bias # <реализовать логику нейрона>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HJRkSkHHsb7u"},"outputs":[],"source":["inputs = torch.tensor([1.0, 2.0, 3.0, 4.0])\n","weights = torch.tensor([-0.2, 0.3, -0.5, 0.7])\n","bias = 3.14"]},{"cell_type":"code","source":["test_neuron = Neuron(weights, bias)\n","test_neuron.forward(inputs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9gbDEw3NAEvQ","executionInfo":{"status":"ok","timestamp":1676638485145,"user_tz":-180,"elapsed":7,"user":{"displayName":"Даниил Кравченко","userId":"18191217465303191452"}},"outputId":"08134780-d7aa-4ee7-d576-e6e07b6e8e49"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(4.8400)"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["dot_pr = sum([x*y for x,y in zip(weights, inputs)])\n","dot_pr + bias"],"metadata":{"id":"vvoUWxk5A2go","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1676638485146,"user_tz":-180,"elapsed":7,"user":{"displayName":"Даниил Кравченко","userId":"18191217465303191452"}},"outputId":"7fee8243-bdf1-4b14-f8a5-985fc877b98a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(4.8400)"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"1qJvnwiyty37"},"source":["2.1.2 Используя операции над матрицами и векторами из библиотеки `torch`, реализовать полносвязный слой с заданными весами `weights` и `biases`. Прогнать вектор `inputs` через слой и вывести результат. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fVWF3a9vtx90"},"outputs":[],"source":["class Linear:\n","  def __init__(self, weights, biases):\n","    # <создать атрибуты объекта weights и biases>\n","    self.weights = weights\n","    self.biases = biases\n","  \n","  def forward(self, inputs):\n","    return torch.mv(self.weights.T, inputs) + self.biases # <реализовать логику слоя>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fo-JFnHPuFCS"},"outputs":[],"source":["inputs = torch.tensor([1.0, 2.0, 3.0, 4.0])\n","weights = torch.tensor([[-0.2, 0.3, -0.5, 0.7],\n","                        [0.5, -0.91, 0.26, -0.5],\n","                        [-0.26, -0.27, 0.17, 0.87]]).T\n","\n","biases = torch.tensor([3.14, 2.71, 7.2])"]},{"cell_type":"code","source":["l = Linear(weights, biases)\n","l.forward(inputs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SNLqN-c7DAbK","executionInfo":{"status":"ok","timestamp":1676888839924,"user_tz":-180,"elapsed":7,"user":{"displayName":"Даниил Кравченко","userId":"18191217465303191452"}},"outputId":"ab16aba0-cd60-4c53-f39b-cc977c66615e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([ 4.8400,  0.1700, 10.3900])"]},"metadata":{},"execution_count":45}]},{"cell_type":"markdown","metadata":{"id":"mQtsJzcxuyGd"},"source":["2.1.3 Реализовать полносвязный слой из __2.1.2__ таким образом, чтобы он мог принимать на вход матрицу (батч) с данными. Продемонстрировать работу.\n","Результатом прогона сквозь слой должна быть матрица размера `batch_size` x `n_neurons`.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z8IizmtsuhO1"},"outputs":[],"source":["inputs = torch.tensor([[1, 2, 3, 2.5], \n","                       [2, 5, -1, 2], \n","                       [-1.5, 2.7, 3.3, -0.8]])"]},{"cell_type":"code","source":["class Linear:\n","  def __init__(self, weights, biases):\n","    # <создать атрибуты объекта weights и biases>\n","    self.weights = weights\n","    self.biases = biases\n","  \n","  def forward(self, inputs):\n","    return torch.matmul(inputs, self.weights) + self.biases # <реализовать логику слоя>"],"metadata":{"id":"Spcd8aNHibCt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["l = Linear(weights, biases)\n","l.forward(inputs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Hvl_LJ7kQ2K","executionInfo":{"status":"ok","timestamp":1676889869106,"user_tz":-180,"elapsed":444,"user":{"displayName":"Даниил Кравченко","userId":"18191217465303191452"}},"outputId":"6011f117-91c9-4b36-a592-3240791f7bdb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 3.7900,  0.9200,  9.0850],\n","        [ 6.1400, -2.1000,  6.9000],\n","        [ 2.0400,  0.7610,  6.7260]])"]},"metadata":{},"execution_count":78}]},{"cell_type":"markdown","metadata":{"id":"OQ2OxH4_vBLu"},"source":["2.1.4 Используя операции над матрицами и векторами из библиотеки `torch`, реализовать полносвязный слой из `n_neurons` нейронов с `n_features` весами у каждого нейрона (инициализируются из стандартного нормального распределения). Прогнать вектор `inputs` через слой и вывести результат. Результатом прогона сквозь слой должна быть матрица размера `batch_size` x `n_neurons`."]},{"cell_type":"code","execution_count":16,"metadata":{"id":"IOv52EdovASs","executionInfo":{"status":"ok","timestamp":1678093683064,"user_tz":-180,"elapsed":509,"user":{"displayName":"Даниил Кравченко","userId":"18191217465303191452"}}},"outputs":[],"source":["class Linear:\n","  def __init__(self, n_features, n_neurons):\n","    # <создать атрибуты объекта weights и biases>'\n","    self.weights = torch.randn(n_features, n_neurons)\n","    self.biases = torch.randn(n_neurons)\n","\n","  def forward(self, inputs):\n","    return torch.matmul(inputs, self.weights) + self.biases"]},{"cell_type":"code","source":["l = Linear(4, 3)\n","l.forward(inputs)"],"metadata":{"id":"v1ZxHa7uwRBW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1676891886002,"user_tz":-180,"elapsed":5,"user":{"displayName":"Даниил Кравченко","userId":"18191217465303191452"}},"outputId":"dfb41468-6481-4d26-8053-42c5af283a03"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-0.7224,  3.5632,  5.1968],\n","        [ 0.8008,  2.0569,  1.6831],\n","        [-5.3148,  8.3496,  4.7872]])"]},"metadata":{},"execution_count":144}]},{"cell_type":"markdown","metadata":{"id":"IPG4UqL4wajI"},"source":["2.1.5 Используя решение из __2.1.4__, создать 2 полносвязных слоя и пропустить матрицу `inputs` последовательно через эти два слоя. Количество нейронов в первом слое выбрать произвольно, количество нейронов во втором слое выбрать так, чтобы результатом прогона являлась матрица (3x7). "]},{"cell_type":"code","execution_count":3,"metadata":{"id":"RjjQIQlTxJE6","executionInfo":{"status":"ok","timestamp":1678093230935,"user_tz":-180,"elapsed":1,"user":{"displayName":"Даниил Кравченко","userId":"18191217465303191452"}}},"outputs":[],"source":["inputs = torch.tensor([[1, 2, 3, 2.5], \n","                       [2, 5, -1, 2], \n","                       [-1.5, 2.7, 3.3, -0.8]])"]},{"cell_type":"code","source":["l = Linear(4, 7)\n","l2 = Linear(7, 7)\n","l2.forward(l.forward(inputs))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5HME9nLsc1ku","executionInfo":{"status":"ok","timestamp":1676891965574,"user_tz":-180,"elapsed":413,"user":{"displayName":"Даниил Кравченко","userId":"18191217465303191452"}},"outputId":"e965b2e7-cb3d-43a4-cd53-abd45a1c0d31"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 25.0432, -16.0376,  15.3061,  -4.2147,   5.0663,  -7.4036, -11.2173],\n","        [  9.6235, -14.5618,  21.6731,   2.6856,   6.9185,   1.3076, -12.1494],\n","        [ 17.9373, -22.2209,  11.4288, -13.8838,   3.4375, -17.2719,   2.9574]])"]},"metadata":{},"execution_count":148}]},{"cell_type":"markdown","metadata":{"id":"cRVH_2K7xTBC"},"source":["## 2.2 Создание функций активации"]},{"cell_type":"markdown","metadata":{"id":"B9kngE6Fxs9D"},"source":["2.2.1 Используя операции над матрицами и векторами из библиотеки `torch`, реализовать функцию активации ReLU:\n","\n","![](https://wikimedia.org/api/rest_v1/media/math/render/svg/f4353f4e3e484130504049599d2e7b040793e1eb)\n","\n","Создать матрицу размера (4,3), заполненную числами из стандартного нормального распределения, и проверить работоспособность функции активации."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jZLvMRByxSTC"},"outputs":[],"source":["class ReLU:\n","  def forward(self, inputs):\n","    # <реализовать логику ReLU>\n","    return torch.where(inputs < 0, 0, inputs)"]},{"cell_type":"code","source":["r = ReLU()\n","inputs = torch.randn(4, 3)\n","print(inputs)\n","r.forward(inputs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OCq50Ijvj_sV","executionInfo":{"status":"ok","timestamp":1676892259741,"user_tz":-180,"elapsed":7,"user":{"displayName":"Даниил Кравченко","userId":"18191217465303191452"}},"outputId":"fd1ac5d8-e725-4b36-c22b-f15df92201ef"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 1.2132, -0.0512, -0.4215],\n","        [-0.8533, -1.1531,  0.8775],\n","        [ 0.1296,  1.3495,  0.6849],\n","        [-0.8672,  0.2701,  0.7774]])\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([[1.2132, 0.0000, 0.0000],\n","        [0.0000, 0.0000, 0.8775],\n","        [0.1296, 1.3495, 0.6849],\n","        [0.0000, 0.2701, 0.7774]])"]},"metadata":{},"execution_count":151}]},{"cell_type":"markdown","metadata":{"id":"puExCWiKyTtb"},"source":["2.2.2 Используя операции над матрицами и векторами из библиотеки `torch`, реализовать функцию активации softmax:\n","\n","![](https://wikimedia.org/api/rest_v1/media/math/render/svg/6d7500d980c313da83e4117da701bf7c8f1982f5)\n","\n","Создать матрицу размера (4,3), заполненную числами из стандартного нормального распределения, и проверить работоспособность функции активации. Строки матрицы трактовать как выходы линейного слоя некоторого классификатора для 4 различных примеров."]},{"cell_type":"code","execution_count":18,"metadata":{"id":"fXNcFlqqyKHl","executionInfo":{"status":"ok","timestamp":1678093695061,"user_tz":-180,"elapsed":409,"user":{"displayName":"Даниил Кравченко","userId":"18191217465303191452"}}},"outputs":[],"source":["class Softmax:\n","  def forward(self, inputs):\n","    # <реализовать логику Softmax>\n","    e = inputs.exp()\n","    sum = e.sum(1)\n","    \n","    return e / sum.unsqueeze(1)"]},{"cell_type":"code","source":["inputs = torch.randn((4, 3))\n","Softmax().forward(inputs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MXgNJLGcoGZB","executionInfo":{"status":"ok","timestamp":1676893259230,"user_tz":-180,"elapsed":368,"user":{"displayName":"Даниил Кравченко","userId":"18191217465303191452"}},"outputId":"1e554289-d68c-4147-abef-ad89609ce7a5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.0419, 0.7563, 0.2018],\n","        [0.5780, 0.0770, 0.3451],\n","        [0.1885, 0.7789, 0.0326],\n","        [0.6263, 0.1275, 0.2462]])"]},"metadata":{},"execution_count":175}]},{"cell_type":"code","source":["t = torch.tensor([1, 1, 1])"],"metadata":{"id":"zSYnQXX4REC2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vxVK2TYez_Ye"},"source":["2.2.3 Используя операции над матрицами и векторами из библиотеки `torch`, реализовать функцию активации ELU:\n","\n","![](https://wikimedia.org/api/rest_v1/media/math/render/svg/eb23becd37c3602c4838e53f532163279192e4fd)\n","\n","Создать матрицу размера (4,3), заполненную числами из стандартного нормального распределения, и проверить работоспособность функции активации."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NzMz7HDLySxK"},"outputs":[],"source":["class ELU:\n","  def __init__(self, alpha):\n","    # <создать атрибут объекта alpha>\n","    self.alpha = alpha\n","\n","  def forward(self, inputs):\n","    # <реализовать логику ReLU>\n","    return torch.where(inputs < 0, self.alpha*(torch.exp(inputs)-1), inputs)"]},{"cell_type":"code","source":["inputs = torch.randn(4, 3)\n","print(inputs)\n","ELU(2).forward(inputs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AOHHl1uSsfKe","executionInfo":{"status":"ok","timestamp":1676894573018,"user_tz":-180,"elapsed":396,"user":{"displayName":"Даниил Кравченко","userId":"18191217465303191452"}},"outputId":"ecb53c9b-0b80-45d1-bc7e-552b0cb24b3e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 1.1209,  0.3484,  0.3887],\n","        [-0.6215, -2.0774,  0.2921],\n","        [ 0.0324,  1.2661, -0.8889],\n","        [ 1.0133,  2.6500,  0.4714]])\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([[ 1.1209,  0.3484,  0.3887],\n","        [-0.9257, -1.7495,  0.2921],\n","        [ 0.0324,  1.2661, -1.1778],\n","        [ 1.0133,  2.6500,  0.4714]])"]},"metadata":{},"execution_count":182}]},{"cell_type":"markdown","metadata":{"id":"0peh8r-20Pof"},"source":["## 2.3 Создание функции потерь"]},{"cell_type":"markdown","metadata":{"id":"EY-k3eEs0f7f"},"source":["2.3.1 Используя операции над матрицами и векторами из библиотеки `torch`, реализовать функцию потерь MSE:\n","\n","![](https://wikimedia.org/api/rest_v1/media/math/render/svg/e258221518869aa1c6561bb75b99476c4734108e)\n","\n","Создать полносвязный слой с 1 нейроном, прогнать через него батч `inputs` и посчитать значение MSE, трактуя вектор `y` как вектор правильных ответов."]},{"cell_type":"code","execution_count":86,"metadata":{"id":"f9-wdj5Tz-br","executionInfo":{"status":"ok","timestamp":1678094952338,"user_tz":-180,"elapsed":4,"user":{"displayName":"Даниил Кравченко","userId":"18191217465303191452"}}},"outputs":[],"source":["class MSELoss:\n","  def forward(self, y_pred, y_true):\n","    return ((y_true - y_pred)**2).mean().item()"]},{"cell_type":"code","execution_count":87,"metadata":{"id":"NAyuDU9F1Vuz","executionInfo":{"status":"ok","timestamp":1678094952339,"user_tz":-180,"elapsed":4,"user":{"displayName":"Даниил Кравченко","userId":"18191217465303191452"}}},"outputs":[],"source":["inputs = torch.tensor([[1, 2, 3, 2.5], \n","                       [2, 5, -1, 2], \n","                       [-1.5, 2.7, 3.3, -0.8]])\n","\n","y = torch.tensor([2, 3, 4])"]},{"cell_type":"code","source":["l = Linear(inputs.shape[-1], 1)\n","outputs = l.forward(inputs)\n","MSELoss().forward(outputs, y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dWPoyV6JuhkX","executionInfo":{"status":"ok","timestamp":1678094952339,"user_tz":-180,"elapsed":4,"user":{"displayName":"Даниил Кравченко","userId":"18191217465303191452"}},"outputId":"9fd7386e-c270-48d3-c1cb-13be139fa653"},"execution_count":88,"outputs":[{"output_type":"execute_result","data":{"text/plain":["17.50916862487793"]},"metadata":{},"execution_count":88}]},{"cell_type":"markdown","metadata":{"id":"uaR7rILd1eWR"},"source":["2.3.2 Используя операции над матрицами и векторами из библиотеки `torch`, реализовать функцию потерь Categorical Cross-Entropy:\n","\n","<img src=\"https://i.ibb.co/93gy1dN/Screenshot-9.png\" width=\"200\">\n","\n","Создать полносвязный слой с 3 нейронами и прогнать через него батч `inputs`. Полученный результат пропустить через функцию активации softmax. Посчитать значение CCE, трактуя вектор `y` как вектор правильных ответов."]},{"cell_type":"code","execution_count":62,"metadata":{"id":"hQl8pJsT3HcF","executionInfo":{"status":"ok","timestamp":1678094487288,"user_tz":-180,"elapsed":4,"user":{"displayName":"Даниил Кравченко","userId":"18191217465303191452"}}},"outputs":[],"source":["class CategoricalCrossentropyLoss:\n","  def forward(self, y_pred, y_true):\n","    # <реализовать логику CCE>\n","    mul = y_true.unsqueeze(-1) * torch.log(y_pred)\n","    summ = mul.sum(-1)\n","   \n","    return -summ"]},{"cell_type":"code","execution_count":63,"metadata":{"id":"s7Qoupfo1ZGJ","executionInfo":{"status":"ok","timestamp":1678094487585,"user_tz":-180,"elapsed":2,"user":{"displayName":"Даниил Кравченко","userId":"18191217465303191452"}}},"outputs":[],"source":["inputs = torch.tensor([[1, 2, 3, 2.5], \n","                        [2, 5, -1, 2], \n","                        [-1.5, 2.7, 3.3, -0.8]])\n","y = torch.tensor([1, 0, 0])"]},{"cell_type":"code","source":["l = Linear(inputs.shape[-1], 3)\n","outputs = l.forward(inputs)\n","activated_outputs = Softmax().forward(outputs)\n","CategoricalCrossentropyLoss().forward(activated_outputs, y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xRrUsUUUxhpq","executionInfo":{"status":"ok","timestamp":1678094526445,"user_tz":-180,"elapsed":2,"user":{"displayName":"Даниил Кравченко","userId":"18191217465303191452"}},"outputId":"7b607964-0ff5-475f-9d35-cc9cb8dfbb26"},"execution_count":67,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([14.1956, -0.0000, -0.0000])"]},"metadata":{},"execution_count":67}]},{"cell_type":"markdown","metadata":{"id":"fA6dbanf44_4"},"source":["2.3.3 Модифицировать 2.3.1, добавив L2-регуляризацию.\n","\n","![](https://wikimedia.org/api/rest_v1/media/math/render/svg/d92ca2429275bfdc0474523babbafe014ca8b580)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ADsZxD-h4_Os"},"outputs":[],"source":["class MSELossL2:\n","  def __init__(self, lambda_):\n","    # <создать атрибут объекта alpha>\n","    self.lambda_ = lambda_\n","    \n","  def data_loss(self, y_pred, y_true):\n","    # <подсчет первого слагаемого из формулы>\n","    return ((y_pred - y_true.unsqueeze(-1)) ** 2).sum()\n","\n","  def reg_loss(self, layer):\n","    # используйте атрибуты объекта layer, в которых хранятся веса слоя\n","    # <подсчет второго слагаемого из формулы>\n","    return (layer.weights ** 2).sum() * self.lambda_\n","\n","  def forward(self, y_pred, y_true, layer):\n","    return (self.data_loss(y_pred, y_true) + self.reg_loss(layer)).item()"]},{"cell_type":"code","source":["MSELossL2(lambda_=0.1).forward(y_pred=activated_outputs, y_true=y, layer=l)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DH2VxGkfybLr","executionInfo":{"status":"ok","timestamp":1676896079812,"user_tz":-180,"elapsed":4,"user":{"displayName":"Даниил Кравченко","userId":"18191217465303191452"}},"outputId":"9c273dab-751d-4cad-b125-591b1053e3aa"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["4.692996978759766"]},"metadata":{},"execution_count":226}]},{"cell_type":"markdown","metadata":{"id":"w049ZSdR6qQi"},"source":["## 2.4 Обратное распространение ошибки"]},{"cell_type":"markdown","metadata":{"id":"pBtCfSME9W7Q"},"source":["2.4.1 Используя один нейрон и SGD (1 пример за шаг), решите задачу регрессии"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4xmI-QJ66WAF","colab":{"base_uri":"https://localhost:8080/","height":130},"executionInfo":{"status":"error","timestamp":1676311526048,"user_tz":-180,"elapsed":22,"user":{"displayName":"Даниил Кравченко","userId":"18191217465303191452"}},"outputId":"6a47c102-db49-4d7f-c459-9494057c0c53"},"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-21-2dba7d31286e>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    X = # <преобразуйте массивы numpy в тензоры torch с типом torch.float32\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}],"source":["from sklearn.datasets import make_regression\n","\n","X, y, coef = make_regression(n_features=4, n_informative=4, coef=True, bias=0.5)\n","X = # <преобразуйте массивы numpy в тензоры torch с типом torch.float32\n","y = # <преобразуйте массивы numpy в тензоры torch с типом torch.float32"]},{"cell_type":"markdown","metadata":{"id":"KpPSPYSpD9Ey"},"source":["[Граф вычислений для этой задачи](https://i.ibb.co/2dhDxZx/photo-2021-02-15-17-18-04.jpg)"]},{"cell_type":"markdown","metadata":{"id":"Fc1sXtGd_J-y"},"source":["2.4.1.1 Реализуйте класс `SquaredLoss`\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"llFigkqd_JRU"},"outputs":[],"source":["class SquaredLoss:\n","  def forward(self, y_pred, y_true):\n","    return # <реализовать логику MSE>\n","\n","  def backward(self, y_pred, y_true):\n","    self.dinput = # df/dc\n"]},{"cell_type":"markdown","metadata":{"id":"GY7ForfM97UQ"},"source":["2.4.1.2. Модифицируйте класс `Neuron` из __2.1.1__:\n","\n","  1) Сделайте так, чтобы веса нейрона инициализировались из стандартного нормального распределения\n","\n","  2) Реализуйте расчет градиента относительно весов `weights` и `bias`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L0KqxPJU9kAN"},"outputs":[],"source":["class Neuron:\n","  def __init__(self, n_inputs):\n","    # <создать атрибуты объекта weights и bias>\n","    pass\n","  \n","  def forward(self, inputs):\n","    return # <реализовать логику нейрона>\n","  \n","  def backward(self, dvalue):\n","    # dvalue - значение производной, которое приходит нейрону от следующего слоя сети\n","    # в данном случае это будет значение df/dc (созданное методом backwards у объекта MSELoss)\n","    self.dweights = # df/dW\n","    self.dinput =  # df/wX\n","    self.dbias = # df/db\n"]},{"cell_type":"markdown","metadata":{"id":"rKcO4zOLACxM"},"source":["2.4.1.3 Допишите цикл для настройки весов нейрона\n","\n","[SGD](https://ru.wikipedia.org/wiki/%D0%A1%D1%82%D0%BE%D1%85%D0%B0%D1%81%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B9_%D0%B3%D1%80%D0%B0%D0%B4%D0%B8%D0%B5%D0%BD%D1%82%D0%BD%D1%8B%D0%B9_%D1%81%D0%BF%D1%83%D1%81%D0%BA)\n","\n","![](https://wikimedia.org/api/rest_v1/media/math/render/svg/dda3670f8a8996a0d3bf80856bb4a166cc8db6d4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_g_FvwvmALJd"},"outputs":[],"source":["n_inputs = # <размерность элемента выборки >\n","learning_rate = 0.1 #  скорость обучения\n","n_epoch = 100 #  количество эпох\n","\n","neuron = Neuron(n_inputs)\n","loss = MSELoss()\n","\n","losses = []\n","for epoch in range(100):\n","  for x_example, y_example in zip(X, y):\n","    # forward pass\n","    y_pred = # <прогон через нейрон>\n","    curr_loss = # <прогон через функцию потерь>\n","    losses.append(curr_loss)\n","\n","    # backprop\n","    # <вызов методов backward>\n","    # обратите внимание на последовательность вызовов: от конца к началу\n","\n","    # <шаг оптимизации для весов (weights и bias) нейрона>"]},{"cell_type":"markdown","metadata":{"id":"ebibge9VEgF7"},"source":["2.4.2 Решите задачу 2.4.1, используя пакетный градиентный спуск"]},{"cell_type":"markdown","metadata":{"id":"as-QeWSdOELd"},"source":["Вычисления для этой задачи: \n","[1](https://i.ibb.co/rmtQT6P/photo-2021-02-15-18-00-43.jpg)\n","[2](https://i.ibb.co/NmCFVnQ/photo-2021-02-15-18-01-17.jpg)"]},{"cell_type":"markdown","metadata":{"id":"dr9qq4H_J3zt"},"source":["2.4.1.1 Модифицируйте класс `MSELoss` из __2.3.1__, реализовав расчет производной относительно предыдущего слоя с учетом того, что теперь работа ведется с батчами, а не с индивидуальными примерами\n"," "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L8wjk9iPMQ4x"},"outputs":[],"source":["class MSELoss:\n","  def forward(self, y_pred, y_true):\n","    return # <реализовать логику MSE>\n","\n","  def backward(self, y_pred, y_true):\n","    self.dinput = # df/dy^\n"]},{"cell_type":"markdown","metadata":{"id":"E3fSHCEtJjX8"},"source":["2.4.2.2. Модифицируйте класс `Neuron` из __2.4.1.2__:\n","\n","  1) Реализуйте метод `forward` таким образом, чтобы он мог принимать на вход матрицу (батч) с данными. \n","\n","  2) Реализуйте расчет градиента относительно весов `weights` и `bias` с учетом того, что теперь работа ведется с батчами, а не с индивидуальными примерами"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o_OpuAP0Jpz1"},"outputs":[],"source":["class Neuron:\n","  def __init__(self, n_inputs):\n","    # <создать атрибуты объекта weights и bias>\n","    pass\n","  \n","  def forward(self, inputs):\n","    return # <реализовать логику нейрона>\n","  \n","  def backward(self, dvalue):\n","    # dvalue - значение градиента, которое приходит нейрону от следующего слоя сети\n","    # в данном случае это будет градиент L по y^ (созданный методом backwards у объекта MSELoss)\n","    self.dweights = # df/dW\n","    self.dbias = # df/db\n"]},{"cell_type":"markdown","metadata":{"id":"zO-NZrgKMBFx"},"source":["2.4.2.3 Допишите цикл для настройки весов нейрона"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zqwm_7eqJim1"},"outputs":[],"source":["n_inputs = # <размерность элемента выборки >\n","learning_rate = 0.1 #  скорость обучения\n","n_epoch = 100 #  количество эпох\n","\n","neuron = Neuron(n_inputs)\n","loss = MSELoss()\n","\n","\n","for epoch in range(100):\n","    # forward pass\n","    y_pred = # <прогон через нейрон>\n","    curr_loss = # <прогон через функцию потерь>\n","    losses.append(curr_loss)\n","\n","    # backprop\n","    # <вызов методов backward>\n","    # обратите внимание на последовательность вызовов: от конца к началу\n","\n","    # <шаг оптимизации для весов (weights и bias) нейрона>"]},{"cell_type":"markdown","metadata":{"id":"16VtP159OdMk"},"source":["2.4.3  Используя один полносвязный слой и  пакетный градиетный спуск, решите задачу регрессии из __2.4.1__"]},{"cell_type":"markdown","metadata":{"id":"uj5febreSSZ7"},"source":["2.4.3.1 Модифицируйте класс `Linear` из __2.1.4__. ([вычисление градиентов](https://i.ibb.co/kgVR6m6/photo-2021-02-15-21-30-28.jpg))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9zWuhaLdSB2_"},"outputs":[],"source":["class Linear:\n","  def __init__(self, n_features, n_neurons):\n","    # <создать атрибуты объекта weights и biases>\n","    pass\n","  \n","  def forward(self, inputs):\n","    return # <реализовать логику слоя>\n","\n","  def backward(self, dvalues):\n","    self.dweights = # df/dW\n","    self.dbiases = # df/db\n","    self.dinputs = # df/dX"]},{"cell_type":"markdown","metadata":{"id":"j3w1hT9MS_Lt"},"source":["2.4.3.2 Создайте слой с одним нейроном. Используя класс MSELoss из 2.4.2, убедитесь, что модель обучается"]},{"cell_type":"markdown","metadata":{"id":"RTkJV-F8TVuN"},"source":["2.4.4 Используя наработки из 2.4, создайте нейросеть и решите задачу регрессии.\n","\n","Предлагаемая архитектура: \n","1. Полносвязный слой с 10 нейронами\n","2. Активация ReLU\n","3. Полносвязный слой с 1 нейроном"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"axUjpPz-SvS1"},"outputs":[],"source":["X = torch.linspace(-1, 1, 100).view(-1, 1)\n","y = X.pow(2) + 0.2 * torch.rand(X.size()) "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LXoiNxkpTziV"},"outputs":[],"source":["class Activation_ReLU:\n","  def forward(self, inputs):\n","    self.inputs = inputs\n","    self.output = inputs.clip(min=0)\n","    return self.output\n","  \n","  def backward(self, dvalues):\n","    self.dinputs = dvalues.clone()\n","    self.dinputs[self.inputs <= 0] = 0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tXhspwW6T44T"},"outputs":[],"source":["# создание компонентов сети\n","# fc1 = \n","# relu1 = \n","# fc2 = \n","\n","loss = MSELoss()\n","lr = 0.02\n","\n","ys = []\n","for epoch in range(2001):\n","  # <forward pass>\n","  # fc1 > relu1 > fc2 > loss\n","\n","  data_loss = # <прогон через функцию потерь>\n","\n","  if epoch % 200 == 0:\n","    print(f'epoch {epoch} mean loss {data_loss}')\n","    ys.append(out)\n","  \n","  # <backprop> \n","  # loss > fc2 > relu1 > fc1\n","\n","  # <шаг оптимизации для fc1>\n","\n","  # <шаг оптимизации для fc2>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kpKi0OfoUkwk"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","fig, axs = plt.subplots(len(ys), 1, figsize=(10, 40))\n","for ax, y_ in zip(axs, ys):\n","  ax.scatter(X.numpy(), y.numpy(), color = \"orange\")\n","  ax.plot(X.numpy(), y_.numpy(), 'g-', lw=3)\n","  ax.set_xlim(-1.05, 1.5)\n","  ax.set_ylim(-0.25, 1.25)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"nbformat":4,"nbformat_minor":0}